1. Update streaming threshold to 750 for both methods:
In generateCompletion() method:
- const useStreaming = maxOutputTokens > 1000;
+ const useStreaming = maxOutputTokens > 750;

In generateMultimodalCompletion() method:
- const useStreaming = maxOutputTokens > 1000;
+ const useStreaming = maxOutputTokens > 750;

2. Use type-guard for retry in both methods:
- if (shouldRetry(e)) {
+ if (isSchemaError(e) && shouldRetry(e)) {

3. Remove token estimation and just use actual token counts from response:
Remove these sections:
- // Calculate estimated token count (simple approximation)
- const inputTokens = Math.ceil(prompt.length / 4);
- const outputTokens = Math.ceil(text.length / 4);
- const tokenCount = inputTokens + outputTokens;

And the multimodal version:
- // Calculate estimated token count (simple approximation)
- // Estimate multimodal tokens - images are more expensive
- let inputTokens = 0;
- for (const part of parts) {
-   if (part.type === 'text') {
-     // Text token estimation
-     const content = part.content as string;
-     inputTokens += Math.ceil(content.length / 4);
-   } else if (part.type === 'image') {
-     // Images are much more token-intensive
-     inputTokens += 3000; // Conservative estimate for image tokens
-   } else {
-     // Other file types
-     inputTokens += 1000; // Rough estimate for documents, audio, etc.
-   }
- }
- 
- const outputTokens = Math.ceil(text.length / 4);
- tokenCount = inputTokens + outputTokens;