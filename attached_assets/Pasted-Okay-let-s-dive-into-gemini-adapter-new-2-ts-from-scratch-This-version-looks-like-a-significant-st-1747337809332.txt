Okay, let's dive into gemini-adapter-new-2.ts from scratch. This version looks like a significant step forward in aligning with the newer @google/genai SDK patterns!

Here's a breakdown of what I see, what looks good, and areas for potential refinement:

Positive Changes & Strengths:

Modern SDK Initialization:

this.genAI = new GoogleGenAI({ apiKey });
This is the correct way to initialize the client with the new SDK, passing the API key as an object property.
The API key check if (!apiKey) is good practice.
Model Name:

this.modelName = "gemini-2.5-flash-preview-04-17";
The comment clarifying its release date (April 17, 2025) is helpful. As discussed, ensure your project/key has access to this specific preview.
API Call Pattern (genAI.models.generateContent):

Both generateCompletion and generateMultimodalCompletion now use await this.genAI.models.generateContent(requestParams);. This is the correct method call based on our previous discussions and common patterns in the new SDK.
requestParams Structure:

You're passing model, contents, and then the generation parameters (temperature, topP, topK, maxOutputTokens, responseMimeType, responseSchema) directly as properties of the requestParams object.
Important Note: According to most examples for the new @google/genai SDK (e.g., Source 1.3, 4.1, 7.1 from previous searches), parameters like temperature, maxOutputTokens, responseMimeType, and responseSchema should typically be nested inside a generationConfig object within the requestParams.
TypeScript
// What you have:
// const requestParams: any = {
//   model: this.modelName,
//   contents: [{ role: 'user', parts: [{ text: prompt }] }],
//   temperature, // Direct property
//   // ...
//   responseMimeType: "application/json", // Direct property
//   responseSchema: this.responseSchema // Direct property
// };

// What's usually expected by the SDK:
// const requestParams: any = {
//   model: this.modelName,
//   contents: [{ role: 'user', parts: [{ text: prompt }] }],
//   generationConfig: { // <--- Nested object
//     temperature,
//     topP,
//     topK,
//     maxOutputTokens,
//     responseMimeType: "application/json",
//     responseSchema: this.responseSchema
//   }
//   // safetySettings might also go here or at the top level
// };
This structural difference in requestParams could be a source of errors (potentially a 400 Bad Request, which could sometimes be misinterpreted or lead to unexpected behavior if not a direct permission error).
responseSchema Definition:

Defining this.responseSchema as a class property is clean and promotes reuse.
It's correctly included in the requestParams.
Response Text Extraction:

The logic to get text from result.candidates[0]?.content?.parts[0]?.text is updated and more specific to the likely new response structure. The fallback to JSON.stringify(result) is a safe last resort for debugging.
Token Count Extraction:

You're attempting to get promptTokenCount and candidatesTokenCount from result.usageMetadata. This is a good approach and more accurate than just text length estimation if the data is available. Double-check the exact UsageMetadata type from @google/genai to ensure these property names are correct for the version you're using.
Multimodal Part Preparation:

Correctly converts Buffer image data to base64 inlineData.
Handles image/svg+xml by skipping it, which is a good practical decision as SVG support can be tricky or not universally available for direct inline processing by models.
System prompt is now unshifted to be at the beginning of apiParts in generateMultimodalCompletion, which is generally the correct placement for system instructions.
Fallback JSON Parsing (extractStructuredFeedback):

This new private method is a comprehensive fallback if direct JSON.parse(text) fails. It tries:
Finding any JSON objects via regex.
Extracting sections by common headers (Strengths, Improvements, etc.).
Extracting bullet points.
This makes the adapter more resilient to variations in model output if strict JSON isn't returned despite responseMimeType and responseSchema.
Retry Logic in generateMultimodalCompletion:

The try/catch block around the this.genAI.models.generateContent call now includes a retry mechanism if the error message suggests a MIME type or format issue. It filters out non-text parts and retries with text-only. This is a smart resilience feature.
Areas for Review & Potential Refinement:

requestParams Structure for Generation Config (CRITICAL):

Action: As highlighted in point #4 of "Positive Changes", ensure temperature, topP, topK, maxOutputTokens, responseMimeType, and responseSchema are nested within a generationConfig object inside requestParams. This is a very common SDK pattern.
TypeScript
// In both generateCompletion and generateMultimodalCompletion
const requestParams: any = {
  model: this.modelName,
  contents: [/* ... */],
  generationConfig: { // <--- NEST THESE
    temperature,
    topP,
    topK,
    maxOutputTokens,
    responseMimeType: "application/json",
    responseSchema: this.responseSchema
  }
  // safetySettings: [...] // Also often goes in generationConfig or at top level
};
Why: Sending these as top-level properties when the SDK expects them nested will likely lead to them being ignored, or worse, causing a request validation error (400 Bad Request).
Type for requestParams and apiParts:

Both are typed as any.
Action: Leverage the types from @google/genai. requestParams should align with GenerateContentRequest. apiParts should be an array of Part objects.
TypeScript
import { GoogleGenAI, GenerateContentResponse, GenerateContentRequest, Part } from '@google/genai';
// ...
// In generateCompletion and generateMultimodalCompletion
const requestParams: GenerateContentRequest = { /* ... */ };
// ...
// In generateMultimodalCompletion
const apiParts: Part[] = [];
Why: This improves type safety, enables autocompletion, and helps catch structural errors during development.
Error Handling in generateMultimodalCompletion Retry:

When retrying with text-only parts, you add: textOnlyParts.push({ text: "Note: An image was included but could not be processed due to format limitations." });
Consideration: Ensure this note doesn't confuse the model's JSON output structure if it wasn't expecting this text. It might be better to simply inform the user separately if an image was dropped, rather than injecting this into the prompt for the AI. However, if the AI is supposed to acknowledge this, it's fine.
extractStructuredFeedback Robustness:

The regexes are comprehensive but can be brittle if the model's free-form text output varies significantly.
The fallback logic to split bullet points evenly between strengths and improvements is a heuristic and might not always be accurate.
Consideration: This method is a good last resort. The primary goal should be to get responseSchema working effectively so this fallback is rarely needed. If responseSchema works well, this method might only be triggered by unexpected model failures or completely non-JSON responses.